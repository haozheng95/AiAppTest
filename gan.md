##GAN原理，优缺点、应用总结##
###gan的原理###

原理

GAN的主要灵感来源于博弈论中零和博弈的思想，应用到深度学习神经网络上来说，就是通过生成网络G（Generator）和判别网络D（Discriminator）不断博弈，进而使G学习到数据的分布，如果用到图片生成上，则训练完成后，G可以从一段随机数中生成逼真的图像。G， D的主要功能是： 

- G是一个生成式的网络，它接收一个随机的噪声z（随机数），通过这个噪声生成图像
- D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D（x）代表x为真实图片的概率，如果为1，就代表100%是真实的图片，而输出为0，就代表不可能是真实的图片

训练过程中，生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D。而D的目标就是尽量辨别出G生成的假图像和真实的图像。这样，G和D构成了一个动态的“博弈过程”，最终的平衡点即纳什均衡点.

-- 

纳什均衡

纳什均衡是指博弈中这样的局面，对于每个参与者来说，只要其他人不改变策略，他就无法改善自己的状况。对应的，对于GAN，情况就是生成模型 G 恢复了训练数据的分布（造出了和真实数据一模一样的样本），判别模型再也判别不出来结果，准确率为 50%，约等于乱猜。这是双方网路都得到利益最大化，不再改变自己的策略，也就是不再更新自己的权重。

--

特点

- 相比较传统的模型，他存在两个不同的网络，而不是单一的网络，并且训练方式采用的是对抗训练方式
- GAN中G的梯度更新信息来自判别器D，而不是来自数据样本

###GAN的优缺点###

优点

- 不像贝叶斯生成模型，卷积是一种信息损失的操作，所以用来做识别的卷积神经网络很难再从低维数据生成原始数据。所以GAN这种结构的出现，很大程度上解决了神经网络的生成问题，或者说是第一个用神经网络真正做生成的方法（auto-encoder原始目的只是为了降维，并不是为了生成）。

- GAN是一种生成式模型，相比较其他生成模型（玻尔兹曼机和GSNs）只用到了反向传播,而不需要复杂的马尔科夫链

- 相比其他所有模型, GAN可以产生更加清晰，真实的样本

- GAN采用的是一种无监督的学习方式训练，可以被广泛用在无监督学习和半监督学习领域

- 相比于变分自编码器, GANs没有引入任何决定性偏置( deterministic bias),变分方法引入决定性偏置,因为他们优化对数似然的下界,而不是似然度本身,这看起来导致了VAEs生成的实例比GANs更模糊

- 相比VAE, GANs没有变分下界,如果鉴别器训练良好,那么生成器可以完美的学习到训练样本的分布.换句话说,GANs是渐进一致的,但是VAE是有偏差的

-  GAN应用到一些场景上，比如图片风格迁移，超分辨率，图像补全，去噪，避免了损失函数设计的困难，不管三七二十一，只要有一个的基准，直接上判别器，剩下的就交给对抗训练了。

--

gan的作用

也就是为什么GAN会火了（有部分原因可能是因为Lecun的赞赏）。  
如果GAN只是用来生成一些像真是数据一样的数据的话，那不会有像现在这么火。  
更多的，或者对于机器学习研究员来说，看待的最关键一点应该是GAN可以用来 拟合数据分布。  
什么叫拟合数据分布，就是给你一个训练数据，你能通过GAN这个工具，产生和这个数据分布相似的一些数据。有了拟合数据分布的思想，并在这上面做文章，才是一个真正的机器学习研究人员的素质。比如WGAN，也就是考虑到了GAN是一种拟合数据分布的工具，那么它可能和一些拟合数据分布的函数比如KL散度等是等价的，那么作者朝这个方向进行探索，自然能得出相应的结论，并且提出改进办法，使其成为风靡一时的工作。其实，可以做的工作还有很多，比如，既然你有一个产生类似数据的工具，那么其实你就有了一个做数据增强的工具，也就是对于你的神经网络来说，你有更多的训练数据了。很多人可能会觉得这个想法很简单，其实并不然。因为GAN本身用神经网络训练，如果你能把它融入你的一个任务当中，只用加一些损失函数，其实就能提高你任务上的性能，而且很多人还会觉得你性能好是因为加了神奇的损失函数，其实不过是用GAN做了一些隐式的数据增强吧了。但是你可以随便吹自己的模型是多么厉害，损失函数设计得多么有意义，多绕几下，别人也就忘了不就是GAN增强了数据嘛。因为GAN给各个任务开了一条提高性能的大门，那每把GAN用在一个任务上，就得引用GAN这篇论文，引用量上去了自然就火了。而且原始GAN是难训练或者效果差的，那么这些嗷嗷待哺的任务和相关研究人员自然也会更多关注GAN的发展，以期望在自己的任务上用到最新，最好的技术。所以，最近做提高和改进GAN的工作也取得了极大的关注度。  
那么再解释一下这个工作变火的本质：以前的神经网络存在生成困难的问题，GAN提供了解决办法，该方法简单、强大、适用性广。

--

GAN和VAE的区别  

很多人弄不清楚GAN和VAE的区别，觉得两个模型都可以做生成，为什么GAN会这么火。GAN的目的是为了生成，而VAE目的是为了压缩，目的不同效果自然不同。VAE重构用的L2 loss自然比不上GAN的生成loss。

--

我觉得GAN只是用来拟合数据分布，和人类的灵感创作之类的概念还是不一样的。比如人作画，不是一个像素一个像素地画图，而是借助一些外部工具，比如笔刷，颜料什么的去作画。所以人能很容易地学会画画，并且画出有意义的图片，而GAN到现在还是只能生成一些低分辨率的图片。所以，通用AI应该是一个能够学习如何使用工具的AI。比如，让它通过Photoshop，用Photoshop里面的笔刷工具去生成一幅图片。也就是说，对于自然界的一些高维信息，我们可以用一些比较通用的（预训练的）神经网络先去提取低维特征，然后再去拟合这个低维特征的分布（而不是直接去拟合原始数据的分布）。深度学习发展了这么年，虽然没能出现通用人工智能，至少从原始数据中提取一些低维特征向量还是没问题的，也就是说我们至少做到了通用人工智能的初级感知（相当于动物的本能）。希望下一步，我们能在这些本能的基础上构建更加智慧的通用AI。




--

缺点

- 训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的,但在实践中它还是比训练玻尔兹曼机稳定的多

- GAN不适合处理离散形式的数据，比如文本

- GAN存在训练不稳定、梯度消失、模式崩溃的问题 

--

模式崩溃(model collapse)原因

一般出现在GAN训练不稳定的时候，具体表现为生成出来的结果非常差，但是即使加长训练时间后也无法得到很好的改善。

具体原因可以解释如下： 

- GAN采用的是对抗训练的方式，G的梯度更新来自D，所以G生成的好不好，得看D怎么说。具体就是G生成一个样本，交给D去评判，D会输出生成的假样本是真样本的概率（0-1），相当于告诉G生成的样本有多大的真实性，G就会根据这个反馈不断改善自己，提高D输出的概率值。但是如果某一次G生成的样本可能并不是很真实，但是D给出了正确的评价，或者是G生成的结果中一些特征得到了D的认可，这时候G就会认为我输出的正确的，那么接下来我就这样输出肯定D还会给出比较高的评价，实际上G生成的并不怎么样，但是他们两个就这样自我欺骗下去了，导致最终生成结果缺失一些信息，特征不全。


--

为什么GAN中的优化器不常用SGD

- SGD容易震荡，容易使GAN训练不稳定，

- GAN的目的是在高维非凸的参数空间中找到纳什均衡点，GAN的纳什均衡点是一个鞍点，但是SGD只会找到局部极小值，因为SGD解决的是一个寻找最小值的问题，GAN是一个博弈问题。

--


为什么GAN不适合处理文本数据

- 文本数据相比较图片数据来说是离散的，因为对于文本来说，通常需要将一个词映射为一个高维的向量，最终预测的输出是一个one-hot向量，假设softmax的输出是（0.2， 0.3， 0.1，0.2，0.15，0.05）那么变为onehot是（0，1，0，0，0，0），如果softmax输出是（0.2， 0.25， 0.2， 0.1，0.15，0.1 ），one-hot仍然是（0， 1， 0， 0， 0， 0），所以对于生成器来说，G输出了不同的结果但是D给出了同样的判别结果，并不能将梯度更新信息很好的传递到G中去，所以D最终输出的判别没有意义。

- 另外就是GAN的损失函数是JS散度，JS散度不适合衡量不想交分布之间的距离。

（WGAN虽然使用wassertein距离代替了JS散度，但是在生成文本上能力还是有限，GAN在生成文本上的应用有seq-GAN,和强化学习结合的产物）



###GAN的广泛应用###

- GAN本身是一种生成式模型，所以在数据生成上用的是最普遍的，最常见的是图片生成，常用的有DCGAN WGAN，BEGAN，个人感觉在BEGAN的效果最好而且最简单。

- GAN本身也是一种无监督学习的典范，因此它在无监督学习，半监督学习领域都有广泛的应用

- 不仅在生成领域，GAN在分类领域也占有一席之地，简单来说，就是替换判别器为一个分类器，做多分类任务，而生成器仍然做生成任务，辅助分类器训练

- GAN可以和强化学习结合，目前一个比较好的例子就是seq-GAN  

- 目前比较有意思的应用就是GAN用在图像风格迁移，图像降噪修复，图像超分辨率了，都有比较好的结果，详见pix-2-pix GAN 和cycle GAN。但是GAN目前在视频生成上和预测上还不是很好。

- 目前也有研究者将GAN用在对抗性攻击上，具体就是训练GAN生成对抗文本，有针对或者无针对的欺骗分类器或者检测系统等等，但是目前没有见到很典范的文章  

###GAN应用列表###